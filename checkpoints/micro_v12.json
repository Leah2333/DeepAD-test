{"agent": "ppo", "states": {"type": "float", "shape": [23]}, "actions": {"type": "float", "shape": [4]}, "max_episode_timesteps": 1000, "batch_size": 64, "network": "auto", "use_beta_distribution": false, "memory": "minimum", "update_frequency": "batch_size", "learning_rate": 0.005, "subsampling_fraction": 0.33, "optimization_steps": null, "likelihood_ratio_clipping": 0.25, "discount": 0.999, "predict_terminal_values": false, "baseline": null, "baseline_optimizer": null, "state_preprocessing": "linear_normalization", "reward_preprocessing": null, "exploration": 0.05, "variable_noise": 0.0, "l2_regularization": 0.001, "entropy_regularization": 0.0, "parallel_interactions": 1, "config": null, "saver": null, "summarizer": null, "recorder": null, "internals": {}, "initial_internals": {"policy": {}}}